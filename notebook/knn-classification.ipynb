{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install cuml-cu12 --extra-index-url=https://pypi.nvidia.com\n",
    "!pip install -q pandas matplotlib seaborn scikit-learn xgboost joblib tqdm opencv-python-headless pillow timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Disable albumentations update warning\n",
    "os.environ['NO_ALBUMENTATIONS_UPDATE'] = '1'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# [MỚI] Thêm thư viện cho benchmark\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Import các mô hình Machine Learning của SKLEARN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import joblib  # Thêm thư viện để lưu/tải mô hình\n",
    "\n",
    "# [MỚI] Thử import thư viện CUML (RAPIDS) và CUPY\n",
    "# Chúng sẽ chỉ được sử dụng nếu import thành công\n",
    "try:\n",
    "    import cuml\n",
    "    import cupy as cp\n",
    "    cuml_available = True\n",
    "    print(\"Tìm thấy thư viện CUML và CUPY. Sẽ chạy benchmark trên GPU.\")\n",
    "except ImportError:\n",
    "    cuml_available = False\n",
    "    print(\"Không tìm thấy CUML. Sẽ chỉ chạy các mô hình Sklearn trên CPU.\")\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration for the model and training.\"\"\"\n",
    "    def __init__(self):\n",
    "        # Basic configurations\n",
    "        self.seed = 42\n",
    "        self.image_size = 448\n",
    "        self.batch_size = 16 \n",
    "        self.num_workers = 2\n",
    "        self.model_name = 'tradition_features' \n",
    "        \n",
    "        # [MỚI] Tự động phát hiện thiết bị (mặc dù không dùng cho CNN nữa,\n",
    "        # nhưng tốt để biết có GPU hay không)\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # Paths\n",
    "        self.data_dir = Path(\"/kaggle/input/orange-dataset/Processed_data\")\n",
    "        self.output_dir = Path(\"/kaggle/working\")\n",
    "        \n",
    "        # Categories\n",
    "        self.categories = ['citrus canker', 'healthy', 'melanose']\n",
    "        self.num_classes = len(self.categories)\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "# ==============================================================================\n",
    "# CÁC HÀM TIỆN ÍCH (Giữ nguyên)\n",
    "# ==============================================================================\n",
    "def plot_confusion_matrix(y_true: List[int], y_pred: List[int], class_names: List[str], save_path: str, model_name: str):\n",
    "    \"\"\"Plots and saves the confusion matrix for a specific model.\"\"\"\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 18})\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix for {model_name} saved to {save_path}\")\n",
    "\n",
    "def prepare_data(config: Config) -> Tuple[List, List]:\n",
    "    \"\"\"Prepare data paths and labels.\"\"\"\n",
    "    images, labels = [], []\n",
    "    label_dict = {cat: idx for idx, cat in enumerate(config.categories)}\n",
    "    \n",
    "    print(\"Loading data paths...\")\n",
    "    for category in config.categories:\n",
    "        category_path = config.data_dir / category\n",
    "        image_paths = list(category_path.glob('*.jpg'))\n",
    "        print(f\"{category}: {len(image_paths)} images\")\n",
    "        images.extend(image_paths)\n",
    "        labels.extend([label_dict[category]] * len(image_paths))\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# ==============================================================================\n",
    "# HÀM TRÍCH XUẤT ĐẶC TRƯNG (Giữ nguyên)\n",
    "# ==============================================================================\n",
    "def get_lbp_features(image: np.ndarray, num_points: int = 24, radius: int = 8) -> np.ndarray:\n",
    "    \"\"\"Calculates Local Binary Patterns (LBP) features.\"\"\"\n",
    "    try:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        lbp = cv2.LBP(gray, radius, num_points, method=cv2.LBP_DEFAULT)\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-6)\n",
    "        return hist\n",
    "    except:\n",
    "        return np.zeros(num_points + 2)\n",
    "\n",
    "def get_hog_features(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculates Histogram of Oriented Gradients (HOG) features.\"\"\"\n",
    "    try:\n",
    "        resized_image = cv2.resize(image, (64, 128)) \n",
    "        hog = cv2.HOGDescriptor()\n",
    "        h = hog.compute(resized_image)\n",
    "        return h.flatten()\n",
    "    except:\n",
    "        return np.zeros(3780) \n",
    "\n",
    "def get_color_histogram(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculates color histogram features (3 channels).\"\"\"\n",
    "    try:\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        histograms = []\n",
    "        for i in range(3):\n",
    "            hist = cv2.calcHist([hsv], [i], None, [256], [0, 256])\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "            histograms.append(hist)\n",
    "        return np.concatenate(histograms)\n",
    "    except:\n",
    "        return np.zeros(256 * 3)\n",
    "\n",
    "def extract_traditional_features(images: List[Path]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts HOG, LBP, and Color Histogram features for a list of images.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    print(\"\\nExtracting traditional features...\")\n",
    "    for image_path in tqdm(images):\n",
    "        try:\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            hog_features = get_hog_features(image)\n",
    "            lbp_features = get_lbp_features(image)\n",
    "            color_hist = get_color_histogram(image)\n",
    "\n",
    "            combined_feature = np.concatenate([hog_features, lbp_features, color_hist])\n",
    "            features.append(combined_feature)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "            \n",
    "    # [MỚI] Đảm bảo trả về kiểu float32 để tương thích tốt với cả sklearn và cuml\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "# [MỚI] Hàm để tạo biểu đồ benchmark\n",
    "def plot_benchmark_results(df: pd.DataFrame, output_dir: Path):\n",
    "    \"\"\"Plots and saves benchmark results for time and accuracy.\"\"\"\n",
    "    \n",
    "    # 1. Biểu đồ thời gian (Fit & Predict)\n",
    "    try:\n",
    "        df_melted = df.melt(id_vars=['model', 'library'], value_vars=['fit_time', 'pred_time'],\n",
    "                            var_name='metric', value_name='time_seconds')\n",
    "        \n",
    "        plt.figure(figsize=(18, 10))\n",
    "        sns.catplot(\n",
    "            data=df_melted, \n",
    "            x='model', \n",
    "            y='time_seconds', \n",
    "            hue='library', \n",
    "            col='metric', \n",
    "            kind='bar', \n",
    "            sharey=False\n",
    "        )\n",
    "        plt.suptitle('Benchmark Thời Gian (Fit vs Predict)', y=1.05)\n",
    "        time_plot_path = output_dir / \"benchmark_times.png\"\n",
    "        plt.savefig(time_plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Biểu đồ benchmark thời gian đã lưu tại: {time_plot_path}\")\n",
    "\n",
    "        # 2. Biểu đồ độ chính xác\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        sns.barplot(data=df, x='model', y='accuracy', hue='library')\n",
    "        plt.title('Benchmark Độ Chính Xác (Accuracy)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Model')\n",
    "        plt.legend(title='Library')\n",
    "        plt.tight_layout()\n",
    "        acc_plot_path = output_dir / \"benchmark_accuracy.png\"\n",
    "        plt.savefig(acc_plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Biểu đồ benchmark độ chính xác đã lưu tại: {acc_plot_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi vẽ biểu đồ benchmark: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    global cuml_available\n",
    "    \"\"\"Main function to execute the feature extraction and ML model training pipeline.\"\"\"\n",
    "    config = Config()\n",
    "    \n",
    "    # [MỚI] Khởi tạo danh sách lưu kết quả benchmark\n",
    "    benchmark_results = []\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "    \n",
    "    # 1. Chuẩn bị dữ liệu\n",
    "    images, labels = prepare_data(config)\n",
    "    \n",
    "    # Chia dữ liệu\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        images, labels, test_size=0.3, random_state=config.seed, stratify=labels\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=config.seed, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset splits:\")\n",
    "    print(f\"Train: {len(X_train)} images\")\n",
    "    print(f\"Val:   {len(X_val)} images\")\n",
    "    print(f\"Test:  {len(X_test)} images\")\n",
    "\n",
    "    # Kết hợp train và val để có tập huấn luyện lớn hơn\n",
    "    train_val_images = X_train + X_val\n",
    "    train_val_labels = y_train + y_val\n",
    "    \n",
    "    # 2. Trích xuất đặc trưng truyền thống\n",
    "    X_train_features = extract_traditional_features(train_val_images)\n",
    "    X_test_features = extract_traditional_features(X_test)\n",
    "    \n",
    "    # [MỚI] Chuyển y_train và y_test sang numpy array để dùng chung\n",
    "    y_train_cpu = np.array(train_val_labels, dtype=np.int32)\n",
    "    y_test_cpu = np.array(y_test, dtype=np.int32)\n",
    "    \n",
    "    print(f\"\\nFeature extraction complete.\")\n",
    "    print(f\"Train features shape: {X_train_features.shape}\")\n",
    "    print(f\"Test features shape:  {X_test_features.shape}\")\n",
    "    \n",
    "    # 3. [MỚI] Định nghĩa các mô hình\n",
    "    \n",
    "    # SKLEARN (CPU)\n",
    "    sklearn_models = {\n",
    "        'SVM_Linear': SVC(kernel='linear', random_state=config.seed, probability=True),\n",
    "        'SVM_RBF': SVC(kernel='rbf', random_state=config.seed, probability=True),\n",
    "        'Random_Forest': RandomForestClassifier(n_estimators=100, random_state=config.seed),\n",
    "        'XGBoost': xgb.XGBClassifier(random_state=config.seed, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "        'Logistic_Regression': LogisticRegression(max_iter=1000, random_state=config.seed)\n",
    "    }\n",
    "    \n",
    "    # CUML (GPU) - [MỚI]\n",
    "    cuml_models = {}\n",
    "    if cuml_available:\n",
    "        # [MỚI] Chuyển dữ liệu sang GPU (CUPY)\n",
    "        print(\"\\nĐang chuyển dữ liệu huấn luyện sang GPU cho CUML...\")\n",
    "        try:\n",
    "            X_train_gpu = cp.asarray(X_train_features)\n",
    "            y_train_gpu = cp.asarray(y_train_cpu)\n",
    "            X_test_gpu = cp.asarray(X_test_features)\n",
    "            # y_test_gpu không cần thiết vì predict trả về cupy array, \n",
    "            # chúng ta sẽ chuyển nó về CPU để so sánh với y_test_cpu\n",
    "            \n",
    "            # [MỚI] Định nghĩa các mô hình CUML tương ứng\n",
    "            cuml_models = {\n",
    "                'SVM_Linear': cuml.svm.SVC(kernel='linear', random_state=config.seed, probability=True),\n",
    "                'SVM_RBF': cuml.svm.SVC(kernel='rbf', random_state=config.seed, probability=True),\n",
    "                'Random_Forest': cuml.ensemble.RandomForestClassifier(n_estimators=100, random_state=config.seed),\n",
    "                'KNN': cuml.neighbors.KNeighborsClassifier(n_neighbors=5),\n",
    "                'Logistic_Regression': cuml.linear_model.LogisticRegression(max_iter=1000, random_state=config.seed)\n",
    "                # Lưu ý: XGBoost không phải là một phần của CUML, \n",
    "                # nó là một thư viện riêng biệt có thể chạy trên GPU (tree_method='gpu_hist').\n",
    "                # Chúng ta giữ XGBoost trong sklearn_models để so sánh với các mô hình CUML.\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi chuyển dữ liệu sang GPU hoặc khởi tạo mô hình CUML: {e}\")\n",
    "            cuml_available = False # Tắt cờ nếu có lỗi\n",
    "    \n",
    "    # 4. [MỚI] Vòng lặp huấn luyện SKLEARN (CPU)\n",
    "    print(\"\\n--- Training and Evaluating SKLEARN (CPU) Models ---\")\n",
    "    for model_name, model in sklearn_models.items():\n",
    "        print(f\"\\n--- [SKLEARN] {model_name.replace('_', ' ')} ---\")\n",
    "        \n",
    "        # Huấn luyện và đo thời gian\n",
    "        print(\"Training...\")\n",
    "        start_fit = time.time()\n",
    "        model.fit(X_train_features, y_train_cpu)\n",
    "        fit_time = time.time() - start_fit\n",
    "        \n",
    "        # Dự đoán và đo thời gian\n",
    "        print(\"Predicting...\")\n",
    "        start_pred = time.time()\n",
    "        y_pred = model.predict(X_test_features)\n",
    "        pred_time = time.time() - start_pred\n",
    "        \n",
    "        # Đánh giá\n",
    "        accuracy = accuracy_score(y_test_cpu, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Fit time: {fit_time:.4f}s\")\n",
    "        print(f\"Predict time: {pred_time:.4f}s\")\n",
    "        \n",
    "        # [MỚI] Lưu kết quả benchmark\n",
    "        benchmark_results.append({\n",
    "            'library': 'sklearn (CPU)',\n",
    "            'model': model_name,\n",
    "            'fit_time': fit_time,\n",
    "            'pred_time': pred_time,\n",
    "            'accuracy': accuracy\n",
    "        })\n",
    "        \n",
    "        report = classification_report(\n",
    "            y_test_cpu, \n",
    "            y_pred, \n",
    "            target_names=config.categories,\n",
    "            digits=4\n",
    "        )\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "        \n",
    "        # Lưu classification report\n",
    "        report_path = config.output_dir / f\"classification_report_SKLEARN_{model_name}.txt\"\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(f\"Model: {model_name} (SKLEARN)\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "            f.write(f\"Fit time: {fit_time:.4f}s\\n\")\n",
    "            f.write(f\"Predict time: {pred_time:.4f}s\\n\\n\")\n",
    "            f.write(report)\n",
    "        print(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "        # Vẽ và lưu confusion matrix\n",
    "        cm_path = config.output_dir / f\"confusion_matrix_SKLEARN_{model_name}.png\"\n",
    "        plot_confusion_matrix(\n",
    "            y_true=y_test_cpu,\n",
    "            y_pred=y_pred,\n",
    "            class_names=config.categories,\n",
    "            save_path=cm_path,\n",
    "            model_name=f\"SKLEARN_{model_name}\"\n",
    "        )\n",
    "\n",
    "        # Lưu model đã huấn luyện\n",
    "        model_save_path = config.output_dir / f\"SKLEARN_{model_name}.joblib\"\n",
    "        joblib.dump(model, model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "        # [ĐÃ BỎ] Phần ONNX đã được loại bỏ\n",
    "\n",
    "    # 5. [MỚI] Vòng lặp huấn luyện CUML (GPU)\n",
    "    if cuml_available:\n",
    "        print(\"\\n--- Training and Evaluating CUML (GPU) Models ---\")\n",
    "        for model_name, model in cuml_models.items():\n",
    "            print(f\"\\n--- [CUML] {model_name.replace('_', ' ')} ---\")\n",
    "            \n",
    "            try:\n",
    "                # Huấn luyện và đo thời gian\n",
    "                print(\"Training on GPU...\")\n",
    "                start_fit = time.time()\n",
    "                model.fit(X_train_gpu, y_train_gpu)\n",
    "                fit_time = time.time() - start_fit\n",
    "                \n",
    "                # Dự đoán và đo thời gian\n",
    "                print(\"Predicting on GPU...\")\n",
    "                start_pred = time.time()\n",
    "                y_pred_gpu = model.predict(X_test_gpu)\n",
    "                pred_time = time.time() - start_pred\n",
    "                \n",
    "                # [MỚI] Chuyển kết quả dự đoán từ GPU về CPU để đánh giá\n",
    "                y_pred = y_pred_gpu.get() # .get() chuyển cupy array về numpy array\n",
    "                \n",
    "                # Đánh giá\n",
    "                accuracy = accuracy_score(y_test_cpu, y_pred)\n",
    "                print(f\"Accuracy: {accuracy:.4f}\")\n",
    "                print(f\"Fit time: {fit_time:.4f}s\")\n",
    "                print(f\"Predict time: {pred_time:.4f}s\")\n",
    "                \n",
    "                # [MỚI] Lưu kết quả benchmark\n",
    "                benchmark_results.append({\n",
    "                    'library': 'cuml (GPU)',\n",
    "                    'model': model_name,\n",
    "                    'fit_time': fit_time,\n",
    "                    'pred_time': pred_time,\n",
    "                    'accuracy': accuracy\n",
    "                })\n",
    "                \n",
    "                report = classification_report(\n",
    "                    y_test_cpu, \n",
    "                    y_pred, \n",
    "                    target_names=config.categories,\n",
    "                    digits=4\n",
    "                )\n",
    "                print(\"\\nClassification Report:\")\n",
    "                print(report)\n",
    "                \n",
    "                # Lưu classification report\n",
    "                report_path = config.output_dir / f\"classification_report_CUML_{model_name}.txt\"\n",
    "                with open(report_path, 'w') as f:\n",
    "                    f.write(f\"Model: {model_name} (CUML)\\n\")\n",
    "                    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "                    f.write(f\"Fit time: {fit_time:.4f}s\\n\")\n",
    "                    f.write(f\"Predict time: {pred_time:.4f}s\\n\\n\")\n",
    "                    f.write(report)\n",
    "                print(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "                # Vẽ và lưu confusion matrix\n",
    "                cm_path = config.output_dir / f\"confusion_matrix_CUML_{model_name}.png\"\n",
    "                plot_confusion_matrix(\n",
    "                    y_true=y_test_cpu,\n",
    "                    y_pred=y_pred,\n",
    "                    class_names=config.categories,\n",
    "                    save_path=cm_path,\n",
    "                    model_name=f\"CUML_{model_name}\"\n",
    "                )\n",
    "\n",
    "                # Lưu model đã huấn luyện\n",
    "                model_save_path = config.output_dir / f\"CUML_{model_name}.joblib\"\n",
    "                joblib.dump(model, model_save_path)\n",
    "                print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi huấn luyện/đánh giá mô hình CUML {model_name}: {e}\")\n",
    "\n",
    "    # 6. [MỚI] Tổng kết, lưu và vẽ benchmark\n",
    "    print(\"\\n--- Benchmark Results Summary ---\")\n",
    "    if not benchmark_results:\n",
    "        print(\"Không có kết quả benchmark nào được ghi lại.\")\n",
    "    else:\n",
    "        df_benchmark = pd.DataFrame(benchmark_results)\n",
    "        df_benchmark = df_benchmark.sort_values(by=['model', 'library'])\n",
    "        \n",
    "        print(df_benchmark.to_string())\n",
    "        \n",
    "        # Lưu vào CSV\n",
    "        csv_path = config.output_dir / \"benchmark_results.csv\"\n",
    "        df_benchmark.to_csv(csv_path, index=False)\n",
    "        print(f\"\\nBenchmark results saved to {csv_path}\")\n",
    "        \n",
    "        # Vẽ biểu đồ\n",
    "        plot_benchmark_results(df_benchmark, config.output_dir)\n",
    "\n",
    "    print(\"\\nAll models trained and evaluated successfully!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()global cuml_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T15:18:16.338959Z",
     "iopub.status.busy": "2025-11-11T15:18:16.338620Z",
     "iopub.status.idle": "2025-11-11T15:24:05.429102Z",
     "shell.execute_reply": "2025-11-11T15:24:05.428462Z",
     "shell.execute_reply.started": "2025-11-11T15:18:16.338937Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CUML and CUPY libraries. GPU benchmarking will be enabled.\n",
      "Loading data paths...\n",
      "citrus canker: 2600 images\n",
      "healthy: 2600 images\n",
      "melanose: 2600 images\n",
      "\n",
      "Dataset splits:\n",
      "Train: 5460 images\n",
      "Val:   1170 images\n",
      "Test:  1170 images\n",
      "\n",
      "Extracting traditional features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6630/6630 [04:48<00:00, 22.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting traditional features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1170/1170 [00:57<00:00, 20.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature extraction complete.\n",
      "Train features shape: (6630, 4574)\n",
      "Test features shape:  (1170, 4574)\n",
      "\n",
      "Moving training data to GPU for CUML...\n",
      "\n",
      "--- Training and Evaluating SKLEARN (CPU) Models ---\n",
      "\n",
      "--- [SKLEARN] KNN ---\n",
      "Training...\n",
      "Predicting on 1170 images...\n",
      "Accuracy: 0.8282\n",
      "Fit time: 0.0129s\n",
      "Predict time: 0.8916s\n",
      "Time per Image: 0.000762s\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "citrus canker     0.9686    0.5538    0.7047       390\n",
      "      healthy     0.7727    0.9590    0.8558       390\n",
      "     melanose     0.8186    0.9718    0.8886       390\n",
      "\n",
      "     accuracy                         0.8282      1170\n",
      "    macro avg     0.8533    0.8282    0.8164      1170\n",
      " weighted avg     0.8533    0.8282    0.8164      1170\n",
      "\n",
      "Classification report saved to /kaggle/working/classification_report_SKLEARN_KNN.txt\n",
      "Confusion matrix for SKLEARN_KNN saved to /kaggle/working/confusion_matrix_SKLEARN_KNN.png\n",
      "Model saved to /kaggle/working/SKLEARN_KNN.joblib\n",
      "\n",
      "--- Training and Evaluating CUML (GPU) Models ---\n",
      "\n",
      "--- [CUML] KNN ---\n",
      "Training on GPU...\n",
      "Predicting on 1170 images (GPU)...\n",
      "Accuracy: 0.8282\n",
      "Fit time: 0.0038s\n",
      "Predict time: 0.1295s\n",
      "Time per Image: 0.000111s\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "citrus canker     0.9686    0.5538    0.7047       390\n",
      "      healthy     0.7727    0.9590    0.8558       390\n",
      "     melanose     0.8186    0.9718    0.8886       390\n",
      "\n",
      "     accuracy                         0.8282      1170\n",
      "    macro avg     0.8533    0.8282    0.8164      1170\n",
      " weighted avg     0.8533    0.8282    0.8164      1170\n",
      "\n",
      "Classification report saved to /kaggle/working/classification_report_CUML_KNN.txt\n",
      "Confusion matrix for CUML_KNN saved to /kaggle/working/confusion_matrix_CUML_KNN.png\n",
      "Model saved to /kaggle/working/CUML_KNN.joblib\n",
      "\n",
      "--- Benchmark Results Summary ---\n",
      "         library model  fit_time  pred_time  time_per_image  accuracy\n",
      "1     cuml (GPU)   KNN  0.003827   0.129538        0.000111  0.828205\n",
      "0  sklearn (CPU)   KNN  0.012925   0.891551        0.000762  0.828205\n",
      "\n",
      "Benchmark results saved to /kaggle/working/benchmark_results.csv\n",
      "\n",
      "Generating benchmark plots...\n",
      "Generating Time Plot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n",
      "/tmp/ipykernel_48/3804495497.py:215: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout(rect=[0, 0, 0.9, 1]) # Adjust rect to make space for the legend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time plot saved at: /kaggle/working/benchmark_times.png\n",
      "Generating Accuracy Plot...\n",
      "Accuracy plot saved at: /kaggle/working/benchmark_accuracy.png\n",
      "\n",
      "Plot generation complete! Check the .png files.\n",
      "\n",
      "All models trained and evaluated successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Disable albumentations update warning\n",
    "os.environ['NO_ALBUMENTATIONS_UPDATE'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import benchmarking and timing libraries\n",
    "import time\n",
    "import pandas as pd\n",
    "import joblib # For saving/loading models\n",
    "\n",
    "# Import specific ML model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import RAPIDS (CUML/CUPY) libraries\n",
    "# These will only be used if the import is successful\n",
    "try:\n",
    "    import cuml\n",
    "    import cupy as cp\n",
    "    cuml_available = True\n",
    "    print(\"Found CUML and CUPY libraries. GPU benchmarking will be enabled.\")\n",
    "except ImportError:\n",
    "    cuml_available = False\n",
    "    print(\"CUML not found. Will run Sklearn models on CPU only.\")\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration class for data, models, and training parameters.\"\"\"\n",
    "    def __init__(self):\n",
    "        # Basic configurations\n",
    "        self.seed = 42\n",
    "        self.image_size = 448\n",
    "        self.batch_size = 16 \n",
    "        self.num_workers = 2\n",
    "        self.model_name = 'tradition_features' \n",
    "        \n",
    "        # Auto-detect device (cuda or cpu)\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # Paths\n",
    "        self.data_dir = Path(\"/kaggle/input/orange-dataset/Processed_data\")\n",
    "        self.output_dir = Path(\"/kaggle/working\")\n",
    "        \n",
    "        # Categories\n",
    "        self.categories = ['citrus canker', 'healthy', 'melanose']\n",
    "        self.num_classes = len(self.categories)\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "# ==============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_confusion_matrix(y_true: List[int], y_pred: List[int], class_names: List[str], save_path: str, model_name: str):\n",
    "    \"\"\"Plots and saves the confusion matrix for a specific model.\"\"\"\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 18})\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix for {model_name} saved to {save_path}\")\n",
    "\n",
    "def prepare_data(config: Config) -> Tuple[List, List]:\n",
    "    \"\"\"Prepare data paths and labels.\"\"\"\n",
    "    images, labels = [], []\n",
    "    label_dict = {cat: idx for idx, cat in enumerate(config.categories)}\n",
    "    \n",
    "    print(\"Loading data paths...\")\n",
    "    for category in config.categories:\n",
    "        category_path = config.data_dir / category\n",
    "        image_paths = list(category_path.glob('*.jpg'))\n",
    "        print(f\"{category}: {len(image_paths)} images\")\n",
    "        images.extend(image_paths)\n",
    "        labels.extend([label_dict[category]] * len(image_paths))\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# ==============================================================================\n",
    "# TRADITIONAL FEATURE EXTRACTION\n",
    "# ==============================================================================\n",
    "\n",
    "def get_lbp_features(image: np.ndarray, num_points: int = 24, radius: int = 8) -> np.ndarray:\n",
    "    \"\"\"Calculates Local Binary Patterns (LBP) features.\"\"\"\n",
    "    try:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        lbp = cv2.LBP(gray, radius, num_points, method=cv2.LBP_DEFAULT)\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-6)\n",
    "        return hist\n",
    "    except:\n",
    "        return np.zeros(num_points + 2)\n",
    "\n",
    "def get_hog_features(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculates Histogram of Oriented Gradients (HOG) features.\"\"\"\n",
    "    try:\n",
    "        resized_image = cv2.resize(image, (64, 128)) \n",
    "        hog = cv2.HOGDescriptor()\n",
    "        h = hog.compute(resized_image)\n",
    "        return h.flatten()\n",
    "    except:\n",
    "        return np.zeros(3780) \n",
    "\n",
    "def get_color_histogram(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculates color histogram features (3 channels).\"\"\"\n",
    "    try:\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        histograms = []\n",
    "        for i in range(3):\n",
    "            hist = cv2.calcHist([hsv], [i], None, [256], [0, 256])\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "            histograms.append(hist)\n",
    "        return np.concatenate(histograms)\n",
    "    except:\n",
    "        return np.zeros(256 * 3)\n",
    "\n",
    "def extract_traditional_features(images: List[Path]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts HOG, LBP, and Color Histogram features for a list of images.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    print(\"\\nExtracting traditional features...\")\n",
    "    for image_path in tqdm(images):\n",
    "        try:\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            hog_features = get_hog_features(image)\n",
    "            lbp_features = get_lbp_features(image)\n",
    "            color_hist = get_color_histogram(image)\n",
    "\n",
    "            combined_feature = np.concatenate([hog_features, lbp_features, color_hist])\n",
    "            features.append(combined_feature)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "            \n",
    "    # Ensure float32 for compatibility with sklearn and cuml\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "# ==============================================================================\n",
    "# BENCHMARK PLOTTING\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_benchmark_results(df_benchmark: pd.DataFrame, output_dir: Path):\n",
    "    \"\"\"\n",
    "    Plots and saves benchmark results for time and accuracy using the specified\n",
    "    DataFrame. This function is based on the provided plotting script.\n",
    "    \"\"\"\n",
    "    print(\"\\nGenerating benchmark plots...\")\n",
    "    \n",
    "    try:\n",
    "        # ==============================================================\n",
    "        # 1. PLOT TIME (FIT & PREDICT)\n",
    "        # ==============================================================\n",
    "        print(\"Generating Time Plot...\")\n",
    "        \n",
    "        # Prepare data (melt)\n",
    "        df_melted = df_benchmark.melt(id_vars=['model', 'library'], \n",
    "                                      value_vars=['fit_time', 'pred_time'],\n",
    "                                      var_name='metric', \n",
    "                                      value_name='time_seconds')\n",
    "        \n",
    "        # Rename metrics for readability\n",
    "        df_melted['metric'] = df_melted['metric'].replace({\n",
    "            'fit_time': 'Training Time (Fit)',\n",
    "            'pred_time': 'Prediction Time (Predict)'\n",
    "        })\n",
    "\n",
    "        # Use sns.catplot (FacetGrid)\n",
    "        g = sns.catplot(\n",
    "            data=df_melted, \n",
    "            x='model', \n",
    "            y='time_seconds', \n",
    "            hue='library', \n",
    "            col='metric', \n",
    "            kind='bar', \n",
    "            sharey=False, # Important, as fit and predict times differ significantly\n",
    "            height=6, \n",
    "            aspect=1.1,\n",
    "            legend=False # Disable the default legend to place it manually\n",
    "        )\n",
    "        \n",
    "        # Set a common title\n",
    "        g.fig.suptitle('Benchmark: Time Comparison', y=1.05, fontsize=16)\n",
    "        g.set_axis_labels(\"Model\", \"Time (seconds)\")\n",
    "        g.set_titles(\"{col_name}\")\n",
    "\n",
    "        # Iterate through the axes of the grid and rotate labels\n",
    "        for ax in g.axes.flat:\n",
    "            ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "        # Manually add and position the legend\n",
    "        g.add_legend(title='Library', bbox_to_anchor=(1.02, 0.5), loc='center left', borderaxespad=0.)\n",
    "\n",
    "        # Use tight_layout to ensure everything fits\n",
    "        plt.tight_layout(rect=[0, 0, 0.9, 1]) # Adjust rect to make space for the legend\n",
    "\n",
    "        # Save the new file\n",
    "        time_plot_path = output_dir / \"benchmark_times.png\"\n",
    "        g.savefig(time_plot_path)\n",
    "        plt.close('all') # Close all plots\n",
    "        print(f\"Time plot saved at: {time_plot_path}\")\n",
    "\n",
    "        # ==============================================================\n",
    "        # 2. PLOT ACCURACY\n",
    "        # ==============================================================\n",
    "        print(\"Generating Accuracy Plot...\")\n",
    "        \n",
    "        # Slightly larger figure size to accommodate labels\n",
    "        plt.figure(figsize=(14, 8)) \n",
    "        \n",
    "        sns.barplot(data=df_benchmark, x='model', y='accuracy', hue='library')\n",
    "        \n",
    "        plt.title('Benchmark: Accuracy Comparison', fontsize=16)\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Model')\n",
    "        plt.legend(title='Library', bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.) # Position legend\n",
    "\n",
    "        # Rotate X-axis labels\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "        # Use tight_layout to ensure labels are not cut off\n",
    "        plt.tight_layout(rect=[0, 0, 0.9, 1]) # Adjust rect to make space for the legend\n",
    "        \n",
    "        # Save the new file\n",
    "        acc_plot_path = output_dir / \"benchmark_accuracy.png\"\n",
    "        plt.savefig(acc_plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Accuracy plot saved at: {acc_plot_path}\")\n",
    "        \n",
    "        print(\"\\nPlot generation complete! Check the .png files.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while plotting: {e}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the feature extraction and ML model training pipeline.\"\"\"\n",
    "    global cuml_available \n",
    "\n",
    "    config = Config()\n",
    "    \n",
    "    # Initialize a list to store benchmark results\n",
    "    benchmark_results = []\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "    \n",
    "    # 1. Prepare data\n",
    "    images, labels = prepare_data(config)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        images, labels, test_size=0.3, random_state=config.seed, stratify=labels\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=config.seed, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset splits:\")\n",
    "    print(f\"Train: {len(X_train)} images\")\n",
    "    print(f\"Val:   {len(X_val)} images\")\n",
    "    print(f\"Test:  {len(X_test)} images\")\n",
    "\n",
    "    # Combine train and val for a larger training set\n",
    "    train_val_images = X_train + X_val\n",
    "    train_val_labels = y_train + y_val\n",
    "    \n",
    "    # 2. Extract traditional features\n",
    "    X_train_features = extract_traditional_features(train_val_images)\n",
    "    X_test_features = extract_traditional_features(X_test)\n",
    "    \n",
    "    # Convert labels to numpy arrays for compatibility\n",
    "    y_train_cpu = np.array(train_val_labels, dtype=np.int32)\n",
    "    y_test_cpu = np.array(y_test, dtype=np.int32)\n",
    "    \n",
    "    num_test_images = len(y_test_cpu)\n",
    "    \n",
    "    print(f\"\\nFeature extraction complete.\")\n",
    "    print(f\"Train features shape: {X_train_features.shape}\")\n",
    "    print(f\"Test features shape:  {X_test_features.shape}\")\n",
    "    \n",
    "    # 3. Define models\n",
    "    \n",
    "    # SKLEARN (CPU)\n",
    "    sklearn_models = {\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    }\n",
    "    \n",
    "    # CUML (GPU)\n",
    "    cuml_models = {}\n",
    "    if cuml_available:\n",
    "        # Move data to GPU (CUPY)\n",
    "        print(\"\\nMoving training data to GPU for CUML...\")\n",
    "        try:\n",
    "            X_train_gpu = cp.asarray(X_train_features)\n",
    "            y_train_gpu = cp.asarray(y_train_cpu)\n",
    "            X_test_gpu = cp.asarray(X_test_features)\n",
    "            \n",
    "            # Define CUML models\n",
    "            cuml_models = {\n",
    "                'KNN': cuml.neighbors.KNeighborsClassifier(n_neighbors=5),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving data to GPU or initializing CUML models: {e}\")\n",
    "            cuml_available = False # Disable if error\n",
    "    \n",
    "    # 4. SKLEARN (CPU) Training Loop\n",
    "    print(\"\\n--- Training and Evaluating SKLEARN (CPU) Models ---\")\n",
    "    for model_name, model in sklearn_models.items():\n",
    "        print(f\"\\n--- [SKLEARN] {model_name} ---\")\n",
    "        \n",
    "        # Train and measure time\n",
    "        print(\"Training...\")\n",
    "        start_fit = time.time()\n",
    "        model.fit(X_train_features, y_train_cpu)\n",
    "        fit_time = time.time() - start_fit\n",
    "        \n",
    "        # Predict and measure time\n",
    "        print(f\"Predicting on {num_test_images} images...\")\n",
    "        start_pred = time.time()\n",
    "        y_pred = model.predict(X_test_features)\n",
    "        pred_time = time.time() - start_pred\n",
    "        \n",
    "        # Evaluate\n",
    "        accuracy = accuracy_score(y_test_cpu, y_pred)\n",
    "        time_per_image = pred_time / num_test_images\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Fit time: {fit_time:.4f}s\")\n",
    "        print(f\"Predict time: {pred_time:.4f}s\")\n",
    "        print(f\"Time per Image: {time_per_image:.6f}s\")\n",
    "        \n",
    "        # Store benchmark results\n",
    "        benchmark_results.append({\n",
    "            'library': 'sklearn (CPU)',\n",
    "            'model': model_name,\n",
    "            'fit_time': fit_time,\n",
    "            'pred_time': pred_time,\n",
    "            'time_per_image': time_per_image,\n",
    "            'accuracy': accuracy\n",
    "        })\n",
    "        \n",
    "        report = classification_report(\n",
    "            y_test_cpu, \n",
    "            y_pred, \n",
    "            target_names=config.categories,\n",
    "            digits=4\n",
    "        )\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "        \n",
    "        # Save classification report\n",
    "        report_path = config.output_dir / f\"classification_report_SKLEARN_{model_name}.txt\"\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(f\"Model: {model_name} (SKLEARN)\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "            f.write(f\"Fit time: {fit_time:.4f}s\\n\")\n",
    "            f.write(f\"Predict time: {pred_time:.4f}s\\n\")\n",
    "            f.write(f\"Time per Image: {time_per_image:.6f}s\\n\\n\")\n",
    "            f.write(report)\n",
    "        print(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "        # Plot and save confusion matrix\n",
    "        cm_path = config.output_dir / f\"confusion_matrix_SKLEARN_{model_name}.png\"\n",
    "        plot_confusion_matrix(\n",
    "            y_true=y_test_cpu,\n",
    "            y_pred=y_pred,\n",
    "            class_names=config.categories,\n",
    "            save_path=cm_path,\n",
    "            model_name=f\"SKLEARN_{model_name}\"\n",
    "        )\n",
    "\n",
    "        # Save trained model\n",
    "        model_save_path = config.output_dir / f\"SKLEARN_{model_name}.joblib\"\n",
    "        joblib.dump(model, model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # 5. CUML (GPU) Training Loop\n",
    "    if cuml_available:\n",
    "        print(\"\\n--- Training and Evaluating CUML (GPU) Models ---\")\n",
    "        for model_name, model in cuml_models.items():\n",
    "            print(f\"\\n--- [CUML] {model_name} ---\")\n",
    "            \n",
    "            try:\n",
    "                # Train and measure time\n",
    "                print(\"Training on GPU...\")\n",
    "                start_fit = time.time()\n",
    "                model.fit(X_train_gpu, y_train_gpu)\n",
    "                fit_time = time.time() - start_fit\n",
    "                \n",
    "                # Predict and measure time\n",
    "                print(f\"Predicting on {num_test_images} images (GPU)...\")\n",
    "                start_pred = time.time()\n",
    "                y_pred_gpu = model.predict(X_test_gpu)\n",
    "                pred_time = time.time() - start_pred\n",
    "                \n",
    "                # Move predictions from GPU to CPU for evaluation\n",
    "                y_pred = y_pred_gpu.get() \n",
    "                \n",
    "                # Evaluate\n",
    "                accuracy = accuracy_score(y_test_cpu, y_pred)\n",
    "                time_per_image = pred_time / num_test_images\n",
    "\n",
    "                print(f\"Accuracy: {accuracy:.4f}\")\n",
    "                print(f\"Fit time: {fit_time:.4f}s\")\n",
    "                print(f\"Predict time: {pred_time:.4f}s\")\n",
    "                print(f\"Time per Image: {time_per_image:.6f}s\")\n",
    "                \n",
    "                # Store benchmark results\n",
    "                benchmark_results.append({\n",
    "                    'library': 'cuml (GPU)',\n",
    "                    'model': model_name,\n",
    "                    'fit_time': fit_time,\n",
    "                    'pred_time': pred_time,\n",
    "                    'time_per_image': time_per_image,\n",
    "                    'accuracy': accuracy\n",
    "                })\n",
    "                \n",
    "                report = classification_report(\n",
    "                    y_test_cpu, \n",
    "                    y_pred, \n",
    "                    target_names=config.categories,\n",
    "                    digits=4\n",
    "                )\n",
    "                print(\"\\nClassification Report:\")\n",
    "                print(report)\n",
    "                \n",
    "                # Save classification report\n",
    "                report_path = config.output_dir / f\"classification_report_CUML_{model_name}.txt\"\n",
    "                with open(report_path, 'w') as f:\n",
    "                    f.write(f\"Model: {model_name} (CUML)\\n\")\n",
    "                    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "                    f.write(f\"Fit time: {fit_time:.4f}s\\n\")\n",
    "                    f.write(f\"Predict time: {pred_time:.4f}s\\n\")\n",
    "                    f.write(f\"Time per Image: {time_per_image:.6f}s\\n\\n\")\n",
    "                    f.write(report)\n",
    "                print(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "                # Plot and save confusion matrix\n",
    "                cm_path = config.output_dir / f\"confusion_matrix_CUML_{model_name}.png\"\n",
    "                plot_confusion_matrix(\n",
    "                    y_true=y_test_cpu,\n",
    "                    y_pred=y_pred,\n",
    "                    class_names=config.categories,\n",
    "                    save_path=cm_path,\n",
    "                    model_name=f\"CUML_{model_name}\"\n",
    "                )\n",
    "\n",
    "                # Save trained model\n",
    "                model_save_path = config.output_dir / f\"CUML_{model_name}.joblib\"\n",
    "                joblib.dump(model, model_save_path)\n",
    "                print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error training/evaluating CUML model {model_name}: {e}\")\n",
    "\n",
    "    # 6. Finalize, Save, and Plot Benchmark\n",
    "    print(\"\\n--- Benchmark Results Summary ---\")\n",
    "    if not benchmark_results:\n",
    "        print(\"No benchmark results were recorded.\")\n",
    "    else:\n",
    "        df_benchmark = pd.DataFrame(benchmark_results)\n",
    "        df_benchmark = df_benchmark.sort_values(by=['model', 'library'])\n",
    "        \n",
    "        # Display summary in console\n",
    "        print(df_benchmark.to_string(columns=[\n",
    "            'library', 'model', 'fit_time', 'pred_time', 'time_per_image', 'accuracy'\n",
    "        ]))\n",
    "        \n",
    "        # Save to CSV\n",
    "        csv_path = config.output_dir / \"benchmark_results.csv\"\n",
    "        df_benchmark.to_csv(csv_path, index=False)\n",
    "        print(f\"\\nBenchmark results saved to {csv_path}\")\n",
    "        \n",
    "        # Generate plots\n",
    "        plot_benchmark_results(df_benchmark, config.output_dir)\n",
    "\n",
    "    print(\"\\nAll models trained and evaluated successfully!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8168773,
     "sourceId": 12910082,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
