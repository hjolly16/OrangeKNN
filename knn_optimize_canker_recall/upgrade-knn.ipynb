{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12910082,"sourceType":"datasetVersion","datasetId":8168773}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### =============================================================================\n# IMPORTS\n# =============================================================================\nimport os\n# Disable albumentations update warning\nos.environ['NO_ALBUMENTATIONS_UPDATE'] = '1'\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nfrom PIL import Image\nimport cv2\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom tqdm import tqdm\n\n# Import benchmarking and timing libraries\nimport time\nimport pandas as pd\nimport joblib # For saving/loading models\n\n# Import specific ML model\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler \n\n# Disable CUML (GPU) support\ncuml_available = False\nprint(\"CUML/CUPY support is disabled. Running Sklearn models on CPU only.\")\n\n# =============================================================================\n# CONFIGURATION\n# =============================================================================\nclass Config:\n    \"\"\"Configuration class for data, models, and training parameters.\"\"\"\n    def __init__(self):\n        # Basic configurations\n        self.seed = 42\n        \n        # Paths\n        # NOTE: Adjust these paths if necessary for your environment\n        self.data_dir = Path(\"/kaggle/input/orange-dataset/Processed_data\")\n        self.output_dir = Path(\"/kaggle/working\")\n        \n        # Categories\n        self.categories = ['citrus canker', 'healthy', 'melanose']\n        self.num_classes = len(self.categories)\n        \n        # Create output directory\n        os.makedirs(self.output_dir, exist_ok=True)\n\n# =============================================================================\n# UTILITY FUNCTIONS\n# =============================================================================\n\ndef plot_confusion_matrix(y_true: List[int], y_pred: List[int], class_names: List[str], save_path: str, model_name: str):\n    \"\"\"Plots and saves the confusion matrix for a specific model.\"\"\"\n    plt.rcParams.update({'font.size': 18})\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 18})\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.title(f'Confusion Matrix - {model_name}')\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.close()\n    print(f\"Confusion matrix for {model_name} saved to {save_path}\")\n\ndef prepare_data(config: Config) -> Tuple[List, List]:\n    \"\"\"Prepare data paths and labels.\"\"\"\n    images, labels = [], []\n    label_dict = {cat: idx for idx, cat in enumerate(config.categories)}\n    \n    print(\"Loading data paths...\")\n    for category in config.categories:\n        category_path = config.data_dir / category\n        image_paths = list(category_path.glob('*.jpg'))\n        print(f\"{category}: {len(image_paths)} images\")\n        images.extend(image_paths)\n        labels.extend([label_dict[category]] * len(image_paths))\n    \n    return images, labels\n\n# =============================================================================\n# TRADITIONAL FEATURE EXTRACTION\n# =============================================================================\n\ndef get_lbp_features(image: np.ndarray, num_points: int = 24, radius: int = 8) -> np.ndarray:\n    \"\"\"Calculates Local Binary Patterns (LBP) features using the 'uniform' method.\"\"\"\n    try:\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        lbp = cv2.LBP(gray, radius, num_points, method=cv2.LBP_UNIFORM)\n        (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n        hist = hist.astype(\"float\")\n        hist /= (hist.sum() + 1e-6)\n        return hist # 26 features\n    except:\n        return np.zeros(num_points + 2)\n\ndef get_hog_features(image: np.ndarray) -> np.ndarray:\n    \"\"\"Calculates Histogram of Oriented Gradients (HOG) features.\"\"\"\n    try:\n        resized_image = cv2.resize(image, (64, 128)) \n        hog = cv2.HOGDescriptor()\n        h = hog.compute(resized_image)\n        return h.flatten() # 3780 features\n    except:\n        return np.zeros(3780) \n\ndef get_color_histogram(image: np.ndarray) -> np.ndarray:\n    \"\"\"Calculates a 3-channel HSV color histogram.\"\"\"\n    try:\n        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n        histograms = []\n        for i in range(3):\n            hist = cv2.calcHist([hsv], [i], None, [256], [0, 256])\n            hist = cv2.normalize(hist, hist).flatten()\n            histograms.append(hist)\n        return np.concatenate(histograms) # 768 features\n    except:\n        return np.zeros(256 * 3)\n\ndef extract_traditional_features(images: List[Path]) -> np.ndarray:\n    \"\"\"\n    Extracts and combines HOG, LBP, and Color Histogram features for a list of images.\n    Total features = 3780 + 26 + 768 = 4574\n    \"\"\"\n    features = []\n    print(\"\\nExtracting traditional features...\")\n    for image_path in tqdm(images):\n        try:\n            image = cv2.imread(str(image_path))\n            if image is None:\n                continue\n\n            hog_features = get_hog_features(image)\n            lbp_features = get_lbp_features(image)\n            color_hist = get_color_histogram(image)\n\n            combined_feature = np.concatenate([hog_features, lbp_features, color_hist])\n            features.append(combined_feature)\n        except Exception as e:\n            print(f\"Error processing image {image_path}: {e}\")\n            \n    return np.array(features, dtype=np.float32)\n\n# =============================================================================\n# BENCHMARK PLOTTING\n# =============================================================================\n\ndef plot_benchmark_results(df_benchmark: pd.DataFrame, output_dir: Path):\n    \"\"\"\n    Plots and saves benchmark results for time and accuracy.\n    \"\"\"\n    print(\"\\nGenerating benchmark plots...\")\n    \n    try:\n        # 1. PLOT TIME (FIT & PREDICT)\n        print(\"Generating Time Plot...\")\n        df_melted = df_benchmark.melt(id_vars=['model', 'library'], \n                                      value_vars=['fit_time', 'pred_time'],\n                                      var_name='metric', \n                                      value_name='time_seconds')\n        \n        df_melted['metric'] = df_melted['metric'].replace({\n            'fit_time': 'Training Time (Fit)',\n            'pred_time': 'Prediction Time (Predict)'\n        })\n\n        g = sns.catplot(\n            data=df_melted, \n            x='model', \n            y='time_seconds', \n            hue='library', \n            col='metric', \n            kind='bar', \n            sharey=False, \n            height=6, \n            aspect=1.1,\n            legend=False \n        )\n        \n        g.fig.suptitle('Benchmark: Time Comparison', y=1.05, fontsize=16)\n        g.set_axis_labels(\"Model\", \"Time (seconds)\")\n        g.set_titles(\"{col_name}\")\n\n        for ax in g.axes.flat:\n            ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n\n        g.add_legend(title='Library', bbox_to_anchor=(1.02, 0.5), loc='center left', borderaxespad=0.)\n        plt.tight_layout(rect=[0, 0, 0.9, 1]) \n\n        time_plot_path = output_dir / \"benchmark_times.png\"\n        g.savefig(time_plot_path)\n        plt.close('all')\n        print(f\"Time plot saved at: {time_plot_path}\")\n\n        # 2. PLOT ACCURACY\n        print(\"Generating Accuracy Plot...\")\n        plt.figure(figsize=(14, 8)) \n        \n        sns.barplot(data=df_benchmark, x='model', y='accuracy', hue='library')\n        \n        plt.title('Benchmark: Accuracy Comparison', fontsize=16)\n        plt.ylabel('Accuracy')\n        plt.xlabel('Model')\n        plt.legend(title='Library', bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.)\n        plt.xticks(rotation=45, ha='right')\n        plt.tight_layout(rect=[0, 0, 0.9, 1]) \n        \n        acc_plot_path = output_dir / \"benchmark_accuracy.png\"\n        plt.savefig(acc_plot_path)\n        plt.close()\n        print(f\"Accuracy plot saved at: {acc_plot_path}\")\n        \n        print(\"\\nPlot generation complete.\")\n\n    except Exception as e:\n        print(f\"An error occurred while plotting: {e}\")\n\n\n# =============================================================================\n# MAIN EXECUTION\n# =============================================================================\n\ndef main():\n    \"\"\"Main function to execute the feature extraction and ML model training pipeline.\"\"\"\n    config = Config()\n    \n    benchmark_results = []\n    \n    # Set random seeds for reproducibility\n    torch.manual_seed(config.seed)\n    np.random.seed(config.seed)\n    \n    # 1. Prepare data\n    images, labels = prepare_data(config)\n    \n    # Split data (Train/Val/Test)\n    X_train, X_temp, y_train, y_temp = train_test_split(\n        images, labels, test_size=0.3, random_state=config.seed, stratify=labels\n    )\n    X_val, X_test, y_val, y_test = train_test_split(\n        X_temp, y_temp, test_size=0.5, random_state=config.seed, stratify=y_temp\n    )\n    \n    print(f\"\\nDataset splits:\")\n    print(f\"Train: {len(X_train)} images\")\n    print(f\"Val:   {len(X_val)} images\")\n    print(f\"Test:  {len(X_test)} images\")\n\n    # Combine train and val for a larger training set\n    train_val_images = X_train + X_val\n    train_val_labels = y_train + y_val\n    \n    # 2. Extract traditional features\n    X_train_features = extract_traditional_features(train_val_images)\n    X_test_features = extract_traditional_features(X_test)\n    \n    y_train_cpu = np.array(train_val_labels, dtype=np.int32)\n    y_test_cpu = np.array(y_test, dtype=np.int32)\n    \n    num_test_images = len(y_test_cpu)\n    \n    print(f\"\\nFeature extraction complete.\")\n    print(f\"Train features shape: {X_train_features.shape}\")\n    print(f\"Test features shape:  {X_test_features.shape}\")\n    \n    # ==========================================================================\n    # 3. FEATURE SCALING\n    # Apply StandardScaler (z-score normalization)\n    # ==========================================================================\n    print(\"\\nApplying StandardScaler to features...\")\n    \n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train_features)\n    X_test_scaled = scaler.transform(X_test_features)\n    \n    print(\"Feature scaling complete.\")\n    \n    # Save the scaler for inference\n    joblib.dump(scaler, config.output_dir / \"scaler.joblib\")\n    print(f\"Scaler model saved.\")\n\n    # 4. Define models\n    \n    # SKLEARN (CPU)\n    model_name = \"KNN_Cosine\"\n    sklearn_models = {\n        model_name: KNeighborsClassifier(\n            n_neighbors=5,      # k=5 as requested\n            weights='distance', # Use distance-based weighting\n            metric='cosine',    # Use Cosine Similarity\n            n_jobs=-1           \n        ),\n    }\n    \n    # 5. SKLEARN (CPU) Training Loop\n    print(\"\\n--- Training and Evaluating SKLEARN (CPU) Models ---\")\n    for model_name, model in sklearn_models.items():\n        print(f\"\\n--- [SKLEARN] {model_name} (k=5, weights='distance', Scaled, metric='cosine') ---\")\n        \n        # Train\n        print(\"Training on Scaled Data...\")\n        start_fit = time.time()\n        model.fit(X_train_scaled, y_train_cpu)\n        fit_time = time.time() - start_fit\n        \n        # Predict\n        print(f\"Predicting on {num_test_images} images (Scaled Test data)...\")\n        start_pred = time.time()\n        y_pred = model.predict(X_test_scaled)\n        pred_time = time.time() - start_pred\n        \n        # Evaluate\n        accuracy = accuracy_score(y_test_cpu, y_pred)\n        time_per_image = pred_time / num_test_images\n        \n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Fit time: {fit_time:.4f}s\")\n        print(f\"Predict time: {pred_time:.4f}s\")\n        print(f\"Time per Image: {time_per_image:.6f}s\")\n        \n        # Store benchmark results\n        benchmark_results.append({\n            'library': 'sklearn (CPU)',\n            'model': model_name,\n            'fit_time': fit_time,\n            'pred_time': pred_time,\n            'time_per_image': time_per_image,\n            'accuracy': accuracy\n        })\n        \n        # Classification Report\n        report = classification_report(\n            y_test_cpu, \n            y_pred, \n            target_names=config.categories,\n            digits=4\n        )\n        print(\"\\nClassification Report:\")\n        print(report)\n        \n        # Save classification report\n        report_path = config.output_dir / f\"classification_report_SKLEARN_{model_name}.txt\"\n        with open(report_path, 'w') as f:\n            f.write(f\"Model: {model_name} (SKLEARN, Scaled, metric=cosine)\\n\")\n            f.write(report)\n        print(f\"Classification report saved to {report_path}\")\n\n        # Save confusion matrix\n        cm_path = config.output_dir / f\"confusion_matrix_SKLEARN_{model_name}.png\"\n        plot_confusion_matrix(\n            y_true=y_test_cpu,\n            y_pred=y_pred,\n            class_names=config.categories,\n            save_path=cm_path,\n            model_name=f\"SKLEARN_{model_name}\"\n        )\n\n        # Save trained model\n        model_save_path = config.output_dir / f\"SKLEARN_{model_name}.joblib\"\n        joblib.dump(model, model_save_path)\n        print(f\"Model saved to {model_save_path}\")\n\n    # 6. Finalize, Save, and Plot Benchmark\n    print(\"\\n--- Benchmark Results Summary ---\")\n    if not benchmark_results:\n        print(\"No benchmark results were recorded.\")\n    else:\n        df_benchmark = pd.DataFrame(benchmark_results)\n        df_benchmark = df_benchmark.sort_values(by=['model', 'library'])\n        \n        # Display summary in console\n        print(df_benchmark.to_string(columns=[\n            'library', 'model', 'fit_time', 'pred_time', 'time_per_image', 'accuracy'\n        ]))\n        \n        # Save to CSV\n        csv_path = config.output_dir / \"benchmark_results.csv\"\n        df_benchmark.to_csv(csv_path, index=False)\n        print(f\"\\nBenchmark results saved to {csv_path}\")\n        \n        # Generate plots\n        plot_benchmark_results(df_benchmark, config.output_dir)\n\n    print(\"\\nAll models trained and evaluated successfully!\")\n\nif __name__ == '__main__':\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-15T08:57:58.178011Z","iopub.execute_input":"2025-11-15T08:57:58.178623Z","iopub.status.idle":"2025-11-15T09:05:11.018909Z","shell.execute_reply.started":"2025-11-15T08:57:58.178597Z","shell.execute_reply":"2025-11-15T09:05:11.018210Z"}},"outputs":[{"name":"stdout","text":"CUML/CUPY support is disabled. Running Sklearn models on CPU only.\nLoading data paths...\ncitrus canker: 2600 images\nhealthy: 2600 images\nmelanose: 2600 images\n\nDataset splits:\nTrain: 5460 images\nVal:   1170 images\nTest:  1170 images\n\nExtracting traditional features...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6630/6630 [05:57<00:00, 18.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nExtracting traditional features...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1170/1170 [01:03<00:00, 18.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nFeature extraction complete.\nTrain features shape: (6630, 4574)\nTest features shape:  (1170, 4574)\n\nApplying StandardScaler to features...\nFeature scaling complete.\nScaler model saved.\n\n--- Training and Evaluating SKLEARN (CPU) Models ---\n\n--- [SKLEARN] KNN_Cosine (k=5, weights='distance', Scaled, metric='cosine') ---\nTraining on Scaled Data...\nPredicting on 1170 images (Scaled Test data)...\nAccuracy: 0.9248\nFit time: 0.0131s\nPredict time: 0.5684s\nTime per Image: 0.000486s\n\nClassification Report:\n               precision    recall  f1-score   support\n\ncitrus canker     0.9626    0.8590    0.9079       390\n      healthy     0.8621    0.9615    0.9091       390\n     melanose     0.9612    0.9538    0.9575       390\n\n     accuracy                         0.9248      1170\n    macro avg     0.9287    0.9248    0.9248      1170\n weighted avg     0.9287    0.9248    0.9248      1170\n\nClassification report saved to /kaggle/working/classification_report_SKLEARN_KNN_Cosine.txt\nConfusion matrix for SKLEARN_KNN_Cosine saved to /kaggle/working/confusion_matrix_SKLEARN_KNN_Cosine.png\nModel saved to /kaggle/working/SKLEARN_KNN_Cosine.joblib\n\n--- Benchmark Results Summary ---\n         library       model  fit_time  pred_time  time_per_image  accuracy\n0  sklearn (CPU)  KNN_Cosine  0.013054   0.568369        0.000486  0.924786\n\nBenchmark results saved to /kaggle/working/benchmark_results.csv\n\nGenerating benchmark plots...\nGenerating Time Plot...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:645: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  g_vals = grouped_vals.get_group(g)\n/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:645: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  g_vals = grouped_vals.get_group(g)\n/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:645: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  g_vals = grouped_vals.get_group(g)\n/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:645: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  g_vals = grouped_vals.get_group(g)\n/usr/local/lib/python3.11/dist-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n/tmp/ipykernel_48/1729242966.py:197: UserWarning: The figure layout has changed to tight\n  plt.tight_layout(rect=[0, 0, 0.9, 1])\n/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:645: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  g_vals = grouped_vals.get_group(g)\n/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:645: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  g_vals = grouped_vals.get_group(g)\n","output_type":"stream"},{"name":"stdout","text":"Time plot saved at: /kaggle/working/benchmark_times.png\nGenerating Accuracy Plot...\nAccuracy plot saved at: /kaggle/working/benchmark_accuracy.png\n\nPlot generation complete.\n\nAll models trained and evaluated successfully!\n","output_type":"stream"}],"execution_count":1}]}