{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12910082,"sourceType":"datasetVersion","datasetId":8168773}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip install cuml-cu12 --extra-index-url=https://pypi.nvidia.com\n\n!pip install cupy-cuda12x\n\n!pip install -q pandas matplotlib seaborn scikit-learn xgboost joblib tqdm opencv-python-headless pillow timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n!pip install numpy==1.26.4","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n# Disable albumentations update warning\nos.environ['NO_ALBUMENTATIONS_UPDATE'] = '1'\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nfrom PIL import Image\nimport cv2\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom tqdm import tqdm\n\n# Import benchmarking and timing libraries\nimport time\nimport pandas as pd\nimport joblib # For saving/loading models\n\n# Import specific ML model\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Import RAPIDS (CUML/CUPY) libraries\n# These will only be used if the import is successful\ntry:\n    import cuml\n    import cupy as cp\n    cuml_available = True\n    print(\"Found CUML and CUPY libraries. GPU benchmarking will be enabled.\")\nexcept ImportError:\n    cuml_available = False\n    print(\"CUML not found. Will run Sklearn models on CPU only.\")\n\nclass Config:\n    \"\"\"Configuration class for data, models, and training parameters.\"\"\"\n    def __init__(self):\n        # Basic configurations\n        self.seed = 42\n        self.image_size = 448\n        self.batch_size = 16 \n        self.num_workers = 2\n        self.model_name = 'tradition_features' \n        \n        # Auto-detect device (cuda or cpu)\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        \n        # Paths\n        self.data_dir = Path(\"/kaggle/input/orange-dataset/Processed_data\")\n        self.output_dir = Path(\"/kaggle/working\")\n        \n        # Categories\n        self.categories = ['citrus canker', 'healthy', 'melanose']\n        self.num_classes = len(self.categories)\n        \n        # Create output directory\n        os.makedirs(self.output_dir, exist_ok=True)\n\n# ==============================================================================\n# UTILITY FUNCTIONS\n# ==============================================================================\n\ndef plot_confusion_matrix(y_true: List[int], y_pred: List[int], class_names: List[str], save_path: str, model_name: str):\n    \"\"\"Plots and saves the confusion matrix for a specific model.\"\"\"\n    plt.rcParams.update({'font.size': 18})\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 18})\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.title(f'Confusion Matrix - {model_name}')\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.close()\n    print(f\"Confusion matrix for {model_name} saved to {save_path}\")\n\ndef prepare_data(config: Config) -> Tuple[List, List]:\n    \"\"\"Prepare data paths and labels.\"\"\"\n    images, labels = [], []\n    label_dict = {cat: idx for idx, cat in enumerate(config.categories)}\n    \n    print(\"Loading data paths...\")\n    for category in config.categories:\n        category_path = config.data_dir / category\n        image_paths = list(category_path.glob('*.jpg'))\n        print(f\"{category}: {len(image_paths)} images\")\n        images.extend(image_paths)\n        labels.extend([label_dict[category]] * len(image_paths))\n    \n    return images, labels\n\n# ==============================================================================\n# TRADITIONAL FEATURE EXTRACTION\n# ==============================================================================\n\ndef get_lbp_features(image: np.ndarray, num_points: int = 24, radius: int = 8) -> np.ndarray:\n    \"\"\"Calculates Local Binary Patterns (LBP) features.\"\"\"\n    try:\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        lbp = cv2.LBP(gray, radius, num_points, method=cv2.LBP_DEFAULT)\n        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n        hist = hist.astype(\"float\")\n        hist /= (hist.sum() + 1e-6)\n        return hist\n    except:\n        return np.zeros(num_points + 2)\n\ndef get_hog_features(image: np.ndarray) -> np.ndarray:\n    \"\"\"Calculates Histogram of Oriented Gradients (HOG) features.\"\"\"\n    try:\n        resized_image = cv2.resize(image, (64, 128)) \n        hog = cv2.HOGDescriptor()\n        h = hog.compute(resized_image)\n        return h.flatten()\n    except:\n        return np.zeros(3780) \n\ndef get_color_histogram(image: np.ndarray) -> np.ndarray:\n    \"\"\"Calculates color histogram features (3 channels).\"\"\"\n    try:\n        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n        histograms = []\n        for i in range(3):\n            hist = cv2.calcHist([hsv], [i], None, [256], [0, 256])\n            hist = cv2.normalize(hist, hist).flatten()\n            histograms.append(hist)\n        return np.concatenate(histograms)\n    except:\n        return np.zeros(256 * 3)\n\ndef extract_traditional_features(images: List[Path]) -> np.ndarray:\n    \"\"\"\n    Extracts HOG, LBP, and Color Histogram features for a list of images.\n    \"\"\"\n    features = []\n    print(\"\\nExtracting traditional features...\")\n    for image_path in tqdm(images):\n        try:\n            image = cv2.imread(str(image_path))\n            if image is None:\n                continue\n\n            hog_features = get_hog_features(image)\n            lbp_features = get_lbp_features(image)\n            color_hist = get_color_histogram(image)\n\n            combined_feature = np.concatenate([hog_features, lbp_features, color_hist])\n            features.append(combined_feature)\n        except Exception as e:\n            print(f\"Error processing image {image_path}: {e}\")\n            \n    # Ensure float32 for compatibility with sklearn and cuml\n    return np.array(features, dtype=np.float32)\n\n# ==============================================================================\n# BENCHMARK PLOTTING\n# ==============================================================================\n\ndef plot_benchmark_results(df_benchmark: pd.DataFrame, output_dir: Path):\n    \"\"\"\n    Plots and saves benchmark results for time and accuracy using the specified\n    DataFrame. This function is based on the provided plotting script.\n    \"\"\"\n    print(\"\\nGenerating benchmark plots...\")\n    \n    try:\n        # ==============================================================\n        # 1. PLOT TIME (FIT & PREDICT)\n        # ==============================================================\n        print(\"Generating Time Plot...\")\n        \n        # Prepare data (melt)\n        df_melted = df_benchmark.melt(id_vars=['model', 'library'], \n                                      value_vars=['fit_time', 'pred_time'],\n                                      var_name='metric', \n                                      value_name='time_seconds')\n        \n        # Rename metrics for readability\n        df_melted['metric'] = df_melted['metric'].replace({\n            'fit_time': 'Training Time (Fit)',\n            'pred_time': 'Prediction Time (Predict)'\n        })\n\n        # Use sns.catplot (FacetGrid)\n        g = sns.catplot(\n            data=df_melted, \n            x='model', \n            y='time_seconds', \n            hue='library', \n            col='metric', \n            kind='bar', \n            sharey=False, # Important, as fit and predict times differ significantly\n            height=6, \n            aspect=1.1,\n            legend=False # Disable the default legend to place it manually\n        )\n        \n        # Set a common title\n        g.fig.suptitle('Benchmark: Time Comparison', y=1.05, fontsize=16)\n        g.set_axis_labels(\"Model\", \"Time (seconds)\")\n        g.set_titles(\"{col_name}\")\n\n        # Iterate through the axes of the grid and rotate labels\n        for ax in g.axes.flat:\n            ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n\n        # Manually add and position the legend\n        g.add_legend(title='Library', bbox_to_anchor=(1.02, 0.5), loc='center left', borderaxespad=0.)\n\n        # Use tight_layout to ensure everything fits\n        plt.tight_layout(rect=[0, 0, 0.9, 1]) # Adjust rect to make space for the legend\n\n        # Save the new file\n        time_plot_path = output_dir / \"benchmark_times.png\"\n        g.savefig(time_plot_path)\n        plt.close('all') # Close all plots\n        print(f\"Time plot saved at: {time_plot_path}\")\n\n        # ==============================================================\n        # 2. PLOT ACCURACY\n        # ==============================================================\n        print(\"Generating Accuracy Plot...\")\n        \n        # Slightly larger figure size to accommodate labels\n        plt.figure(figsize=(14, 8)) \n        \n        sns.barplot(data=df_benchmark, x='model', y='accuracy', hue='library')\n        \n        plt.title('Benchmark: Accuracy Comparison', fontsize=16)\n        plt.ylabel('Accuracy')\n        plt.xlabel('Model')\n        plt.legend(title='Library', bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.) # Position legend\n\n        # Rotate X-axis labels\n        plt.xticks(rotation=45, ha='right')\n\n        # Use tight_layout to ensure labels are not cut off\n        plt.tight_layout(rect=[0, 0, 0.9, 1]) # Adjust rect to make space for the legend\n        \n        # Save the new file\n        acc_plot_path = output_dir / \"benchmark_accuracy.png\"\n        plt.savefig(acc_plot_path)\n        plt.close()\n        print(f\"Accuracy plot saved at: {acc_plot_path}\")\n        \n        print(\"\\nPlot generation complete! Check the .png files.\")\n\n    except Exception as e:\n        print(f\"An error occurred while plotting: {e}\")\n\n\n# ==============================================================================\n# MAIN EXECUTION\n# ==============================================================================\n\ndef main():\n    \"\"\"Main function to execute the feature extraction and ML model training pipeline.\"\"\"\n    global cuml_available \n\n    config = Config()\n    \n    # Initialize a list to store benchmark results\n    benchmark_results = []\n    \n    # Set random seeds for reproducibility\n    torch.manual_seed(config.seed)\n    np.random.seed(config.seed)\n    \n    # 1. Prepare data\n    images, labels = prepare_data(config)\n    \n    # Split data\n    X_train, X_temp, y_train, y_temp = train_test_split(\n        images, labels, test_size=0.3, random_state=config.seed, stratify=labels\n    )\n    X_val, X_test, y_val, y_test = train_test_split(\n        X_temp, y_temp, test_size=0.5, random_state=config.seed, stratify=y_temp\n    )\n    \n    print(f\"\\nDataset splits:\")\n    print(f\"Train: {len(X_train)} images\")\n    print(f\"Val:   {len(X_val)} images\")\n    print(f\"Test:  {len(X_test)} images\")\n\n    # Combine train and val for a larger training set\n    train_val_images = X_train + X_val\n    train_val_labels = y_train + y_val\n    \n    # 2. Extract traditional features\n    X_train_features = extract_traditional_features(train_val_images)\n    X_test_features = extract_traditional_features(X_test)\n    \n    # Convert labels to numpy arrays for compatibility\n    y_train_cpu = np.array(train_val_labels, dtype=np.int32)\n    y_test_cpu = np.array(y_test, dtype=np.int32)\n    \n    num_test_images = len(y_test_cpu)\n    \n    print(f\"\\nFeature extraction complete.\")\n    print(f\"Train features shape: {X_train_features.shape}\")\n    print(f\"Test features shape:  {X_test_features.shape}\")\n    \n    # 3. Define models\n    \n    # SKLEARN (CPU)\n    sklearn_models = {\n        'KNN': KNeighborsClassifier(n_neighbors=5),\n    }\n    \n    # CUML (GPU)\n    cuml_models = {}\n    if cuml_available:\n        # Move data to GPU (CUPY)\n        print(\"\\nMoving training data to GPU for CUML...\")\n        try:\n            X_train_gpu = cp.asarray(X_train_features)\n            y_train_gpu = cp.asarray(y_train_cpu)\n            X_test_gpu = cp.asarray(X_test_features)\n            \n            # Define CUML models\n            cuml_models = {\n                'KNN': cuml.neighbors.KNeighborsClassifier(n_neighbors=5),\n            }\n        except Exception as e:\n            print(f\"Error moving data to GPU or initializing CUML models: {e}\")\n            cuml_available = False # Disable if error\n    \n    # 4. SKLEARN (CPU) Training Loop\n    print(\"\\n--- Training and Evaluating SKLEARN (CPU) Models ---\")\n    for model_name, model in sklearn_models.items():\n        print(f\"\\n--- [SKLEARN] {model_name} ---\")\n        \n        # Train and measure time\n        print(\"Training...\")\n        start_fit = time.time()\n        model.fit(X_train_features, y_train_cpu)\n        fit_time = time.time() - start_fit\n        \n        # Predict and measure time\n        print(f\"Predicting on {num_test_images} images...\")\n        start_pred = time.time()\n        y_pred = model.predict(X_test_features)\n        pred_time = time.time() - start_pred\n        \n        # Evaluate\n        accuracy = accuracy_score(y_test_cpu, y_pred)\n        time_per_image = pred_time / num_test_images\n        \n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Fit time: {fit_time:.4f}s\")\n        print(f\"Predict time: {pred_time:.4f}s\")\n        print(f\"Time per Image: {time_per_image:.6f}s\")\n        \n        # Store benchmark results\n        benchmark_results.append({\n            'library': 'sklearn (CPU)',\n            'model': model_name,\n            'fit_time': fit_time,\n            'pred_time': pred_time,\n            'time_per_image': time_per_image,\n            'accuracy': accuracy\n        })\n        \n        report = classification_report(\n            y_test_cpu, \n            y_pred, \n            target_names=config.categories,\n            digits=4\n        )\n        print(\"\\nClassification Report:\")\n        print(report)\n        \n        # Save classification report\n        report_path = config.output_dir / f\"classification_report_SKLEARN_{model_name}.txt\"\n        with open(report_path, 'w') as f:\n            f.write(f\"Model: {model_name} (SKLEARN)\\n\")\n            f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n            f.write(f\"Fit time: {fit_time:.4f}s\\n\")\n            f.write(f\"Predict time: {pred_time:.4f}s\\n\")\n            f.write(f\"Time per Image: {time_per_image:.6f}s\\n\\n\")\n            f.write(report)\n        print(f\"Classification report saved to {report_path}\")\n\n        # Plot and save confusion matrix\n        cm_path = config.output_dir / f\"confusion_matrix_SKLEARN_{model_name}.png\"\n        plot_confusion_matrix(\n            y_true=y_test_cpu,\n            y_pred=y_pred,\n            class_names=config.categories,\n            save_path=cm_path,\n            model_name=f\"SKLEARN_{model_name}\"\n        )\n\n        # Save trained model\n        model_save_path = config.output_dir / f\"SKLEARN_{model_name}.joblib\"\n        joblib.dump(model, model_save_path)\n        print(f\"Model saved to {model_save_path}\")\n\n    # 5. CUML (GPU) Training Loop\n    if cuml_available:\n        print(\"\\n--- Training and Evaluating CUML (GPU) Models ---\")\n        for model_name, model in cuml_models.items():\n            print(f\"\\n--- [CUML] {model_name} ---\")\n            \n            try:\n                # Train and measure time\n                print(\"Training on GPU...\")\n                start_fit = time.time()\n                model.fit(X_train_gpu, y_train_gpu)\n                fit_time = time.time() - start_fit\n                \n                # Predict and measure time\n                print(f\"Predicting on {num_test_images} images (GPU)...\")\n                start_pred = time.time()\n                y_pred_gpu = model.predict(X_test_gpu)\n                pred_time = time.time() - start_pred\n                \n                # Move predictions from GPU to CPU for evaluation\n                y_pred = y_pred_gpu.get() \n                \n                # Evaluate\n                accuracy = accuracy_score(y_test_cpu, y_pred)\n                time_per_image = pred_time / num_test_images\n\n                print(f\"Accuracy: {accuracy:.4f}\")\n                print(f\"Fit time: {fit_time:.4f}s\")\n                print(f\"Predict time: {pred_time:.4f}s\")\n                print(f\"Time per Image: {time_per_image:.6f}s\")\n                \n                # Store benchmark results\n                benchmark_results.append({\n                    'library': 'cuml (GPU)',\n                    'model': model_name,\n                    'fit_time': fit_time,\n                    'pred_time': pred_time,\n                    'time_per_image': time_per_image,\n                    'accuracy': accuracy\n                })\n                \n                report = classification_report(\n                    y_test_cpu, \n                    y_pred, \n                    target_names=config.categories,\n                    digits=4\n                )\n                print(\"\\nClassification Report:\")\n                print(report)\n                \n                # Save classification report\n                report_path = config.output_dir / f\"classification_report_CUML_{model_name}.txt\"\n                with open(report_path, 'w') as f:\n                    f.write(f\"Model: {model_name} (CUML)\\n\")\n                    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n                    f.write(f\"Fit time: {fit_time:.4f}s\\n\")\n                    f.write(f\"Predict time: {pred_time:.4f}s\\n\")\n                    f.write(f\"Time per Image: {time_per_image:.6f}s\\n\\n\")\n                    f.write(report)\n                print(f\"Classification report saved to {report_path}\")\n\n                # Plot and save confusion matrix\n                cm_path = config.output_dir / f\"confusion_matrix_CUML_{model_name}.png\"\n                plot_confusion_matrix(\n                    y_true=y_test_cpu,\n                    y_pred=y_pred,\n                    class_names=config.categories,\n                    save_path=cm_path,\n                    model_name=f\"CUML_{model_name}\"\n                )\n\n                # Save trained model\n                model_save_path = config.output_dir / f\"CUML_{model_name}.joblib\"\n                joblib.dump(model, model_save_path)\n                print(f\"Model saved to {model_save_path}\")\n\n            except Exception as e:\n                print(f\"Error training/evaluating CUML model {model_name}: {e}\")\n\n    # 6. Finalize, Save, and Plot Benchmark\n    print(\"\\n--- Benchmark Results Summary ---\")\n    if not benchmark_results:\n        print(\"No benchmark results were recorded.\")\n    else:\n        df_benchmark = pd.DataFrame(benchmark_results)\n        df_benchmark = df_benchmark.sort_values(by=['model', 'library'])\n        \n        # Display summary in console\n        print(df_benchmark.to_string(columns=[\n            'library', 'model', 'fit_time', 'pred_time', 'time_per_image', 'accuracy'\n        ]))\n        \n        # Save to CSV\n        csv_path = config.output_dir / \"benchmark_results.csv\"\n        df_benchmark.to_csv(csv_path, index=False)\n        print(f\"\\nBenchmark results saved to {csv_path}\")\n        \n        # Generate plots\n        plot_benchmark_results(df_benchmark, config.output_dir)\n\n    print(\"\\nAll models trained and evaluated successfully!\")\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:18:16.338620Z","iopub.execute_input":"2025-11-11T15:18:16.338959Z","iopub.status.idle":"2025-11-11T15:24:05.429102Z","shell.execute_reply.started":"2025-11-11T15:18:16.338937Z","shell.execute_reply":"2025-11-11T15:24:05.428462Z"}},"outputs":[{"name":"stdout","text":"Found CUML and CUPY libraries. GPU benchmarking will be enabled.\nLoading data paths...\ncitrus canker: 2600 images\nhealthy: 2600 images\nmelanose: 2600 images\n\nDataset splits:\nTrain: 5460 images\nVal:   1170 images\nTest:  1170 images\n\nExtracting traditional features...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6630/6630 [04:48<00:00, 22.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nExtracting traditional features...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1170/1170 [00:57<00:00, 20.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nFeature extraction complete.\nTrain features shape: (6630, 4574)\nTest features shape:  (1170, 4574)\n\nMoving training data to GPU for CUML...\n\n--- Training and Evaluating SKLEARN (CPU) Models ---\n\n--- [SKLEARN] KNN ---\nTraining...\nPredicting on 1170 images...\nAccuracy: 0.8282\nFit time: 0.0129s\nPredict time: 0.8916s\nTime per Image: 0.000762s\n\nClassification Report:\n               precision    recall  f1-score   support\n\ncitrus canker     0.9686    0.5538    0.7047       390\n      healthy     0.7727    0.9590    0.8558       390\n     melanose     0.8186    0.9718    0.8886       390\n\n     accuracy                         0.8282      1170\n    macro avg     0.8533    0.8282    0.8164      1170\n weighted avg     0.8533    0.8282    0.8164      1170\n\nClassification report saved to /kaggle/working/classification_report_SKLEARN_KNN.txt\nConfusion matrix for SKLEARN_KNN saved to /kaggle/working/confusion_matrix_SKLEARN_KNN.png\nModel saved to /kaggle/working/SKLEARN_KNN.joblib\n\n--- Training and Evaluating CUML (GPU) Models ---\n\n--- [CUML] KNN ---\nTraining on GPU...\nPredicting on 1170 images (GPU)...\nAccuracy: 0.8282\nFit time: 0.0038s\nPredict time: 0.1295s\nTime per Image: 0.000111s\n\nClassification Report:\n               precision    recall  f1-score   support\n\ncitrus canker     0.9686    0.5538    0.7047       390\n      healthy     0.7727    0.9590    0.8558       390\n     melanose     0.8186    0.9718    0.8886       390\n\n     accuracy                         0.8282      1170\n    macro avg     0.8533    0.8282    0.8164      1170\n weighted avg     0.8533    0.8282    0.8164      1170\n\nClassification report saved to /kaggle/working/classification_report_CUML_KNN.txt\nConfusion matrix for CUML_KNN saved to /kaggle/working/confusion_matrix_CUML_KNN.png\nModel saved to /kaggle/working/CUML_KNN.joblib\n\n--- Benchmark Results Summary ---\n         library model  fit_time  pred_time  time_per_image  accuracy\n1     cuml (GPU)   KNN  0.003827   0.129538        0.000111  0.828205\n0  sklearn (CPU)   KNN  0.012925   0.891551        0.000762  0.828205\n\nBenchmark results saved to /kaggle/working/benchmark_results.csv\n\nGenerating benchmark plots...\nGenerating Time Plot...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n/tmp/ipykernel_48/3804495497.py:215: UserWarning: The figure layout has changed to tight\n  plt.tight_layout(rect=[0, 0, 0.9, 1]) # Adjust rect to make space for the legend\n","output_type":"stream"},{"name":"stdout","text":"Time plot saved at: /kaggle/working/benchmark_times.png\nGenerating Accuracy Plot...\nAccuracy plot saved at: /kaggle/working/benchmark_accuracy.png\n\nPlot generation complete! Check the .png files.\n\nAll models trained and evaluated successfully!\n","output_type":"stream"}],"execution_count":13}]}